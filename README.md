# MIPT2025_DE_exam
Project for Data Engineering exam, June 2025

Датасет состоит из 569 строк и 32 колонок, из которых первая — ID пациента, вторая — таргет ('M' означает злокачественную опухоль, 'B' – доброкачественную), остальные столбцы  числовые признаки (float). На этом датасете решается задача бинарной классификации.

Наша задача — обучить модель, рассчитать и сохранить ее метрики.

Поскольку задачей данной работы является не достижение высокого качества модели, а демонстрация работы Airflow, этапы EDA и обучения модели сведены к минимуму.

Пайплайн, который мы автоматизируем, состоит из следующих этапов:

Этап 1: Загрузка и EDA: 
1) скачивание исходного датасета в сети Интернет;
2) проверка формата датасета (количество и тип столбцов, уникальные значения таргета);
3) сохранение проверенного датасета на локальном диске.

Этап 2: Очистка и предобработка данных:
1) удаление пропусков и дубликатов;
2) преобразование таргета в числовой бинарный вид (0 или 1);
3) разделение выборки на обучающую и тестовую, выделение таргета в отдельный массив, удаление столбца с ID как излишнего для обучения модели.
4) сохранение полученных массивов (X_train, X_test, y_train, y_test) на локальном диске.
Нормализацию данных делаем на следующих этапах, так как это более оптимально объединить в одном пайплайне, обученном на трейне.

Этап 3: Обучение модели:
1) нормализация обучающего массива методом StandardScaler из библиотеки sklearn;
2) обучение модели логистической регрессии. Обучаем с параметрами по умолчанию, без подбора гиперпараметров, так как это не цель данной работы и позволяет сократить время выполнения кода.
Указанные два шага объединяем в объект Pipeline библиотеки sklearn.
3) сохраняем обученный Pipeline sklearn на локальном диске в формате joblib

Этап 4: Валидация модели:
1) расчет метрик на тестовой выборке;
2) сохранение метрик и параметров обученной модели на локальном диске в формате json.

Выполнение пайплайна линейное, последовательное:
Этап 1 -> Этап 2  -> Этап 3  -> Этап 4

Взаимосвязи между этапами:

Этап 2  использует сохраненный локально на Этапе 1 исходный проверенный датасет в формате csv.

Этап 3 использует сохраненные локально на Этапе 2 очищенные массивы X_train, y_train в формате .csv.

Этап 4 использует сохраненные локально на Этапе 2 очищенные массивы X_test, y_test в формате .csv, а также сохраненный локально на Этапе 3 pipeline в формате joblib.

Результатом выполнения пайплайна являются сохраненные локально в папке results артефакты по результатам обученной модели: метрики обученной модели в формате json, параметры обученного пайплайна (нормализация + логистическая регрессия) в формате json, обученная модель в формате  joblib.
