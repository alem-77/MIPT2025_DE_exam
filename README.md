# MIPT2025_DE_exam
Project for Data Engineering exam, June 2025

Датасет состоит из 569 строк и 32 колонок, из которых первая — ID пациента, вторая — таргет ('M' означает злокачественную опухоль, 'B' – доброкачественную), остальные столбцы  числовые признаки (float). На этом датасете решается задача бинарной классификации.

Наша задача — обучить модель, рассчитать и сохранить ее метрики с использованием Apache Airflow.

Поскольку задачей данной работы является не достижение высокого качества модели, а демонстрация работы Airflow, этапы EDA и обучения модели сведены к минимуму.

Пайплайн, который мы автоматизируем, состоит из следующих этапов:

Этап 1: Загрузка и EDA: 
1) скачивание исходного датасета в сети Интернет;
2) проверка формата датасета (количество и тип столбцов, уникальные значения таргета);
3) сохранение проверенного датасета на локальном диске.

Этап 2: Очистка и предобработка данных:
1) удаление пропусков и дубликатов;
2) преобразование таргета в числовой бинарный вид (0 или 1);
3) разделение выборки на обучающую и тестовую, выделение таргета в отдельный массив, удаление столбца с ID как излишнего для обучения модели.
4) сохранение полученных массивов (X_train, X_test, y_train, y_test) на локальном диске.
Нормализацию данных делаем на следующих этапах, так как это более оптимально объединить в одном пайплайне, обученном на трейне.

Этап 3: Обучение модели:
1) нормализация обучающего массива методом StandardScaler из библиотеки sklearn;
2) обучение модели логистической регрессии. Обучаем с параметрами по умолчанию, без подбора гиперпараметров, так как это не цель данной работы и позволяет сократить время выполнения кода.
Указанные два шага объединяем в объект Pipeline библиотеки sklearn.
3) сохраняем обученный Pipeline sklearn на локальном диске в формате joblib

Этап 4: Валидация модели:
1) расчет метрик на тестовой выборке;
2) сохранение метрик и параметров обученной модели на локальном диске в формате json.

Выполнение пайплайна линейное, последовательное:
Этап 1 -> Этап 2  -> Этап 3  -> Этап 4

Взаимосвязи между этапами:

Этап 2  использует сохраненный локально на Этапе 1 исходный проверенный датасет в формате csv.

Этап 3 использует сохраненные локально на Этапе 2 очищенные массивы X_train, y_train в формате .csv.

Этап 4 использует сохраненные локально на Этапе 2 очищенные массивы X_test, y_test в формате .csv, а также сохраненный локально на Этапе 3 pipeline в формате joblib.

Результатом выполнения пайплайна являются сохраненные локально в папке results артефакты по результатам обученной модели: метрики обученной модели в формате json, параметры обученного пайплайна (нормализация + логистическая регрессия) в формате json, обученная модель в формате  joblib.

Основным скриптом проекта является dag_Martynov_AA.py из папки dags. Это DAG Airflow, который последовательно вызывает 4 Python оператора для выполнения вышеуказанных 4 этапов пайплайна. График запуска DAG по расписанию не составлялся, поскольку у нас модель обучается нерегулярно.

Запуск  DAG осуществляется через Airflow user interface, либо он может быть запущен вручную при работающем Airflow с корректно перенесенными скриптами и папками данного проекта из bash командой airflow dags trigger homework_Martynov_AA , при этом в Airflow DAG не должен быть поставлен на паузу.

Скрипты Python, реализующие каждый из вышеуказанных 4 этапов, размещены в папке etl :
1) load_and_check.py – Этап 1;
2) transform.py — Этап 2;
3) create_model.py — Этап 3;
4) test_model.py — Этап 4.

Скрипты запускаются автоматически из DAG. В случае ошибки предусмотрены повторные попытки запуска каждого из этапов (до 3 попыток). Каждый скрипт предусматривает логирование основных действий с использованием airflow.utils.log.logging_mixin (лог может быть просмотрен в Airflow user interface. Также при работающем Airflow скрипты могут запускаться по отдельности в bash командами airflow tasks test homework_Martynov_AA  <task_id>, где <task_id> - ID этапа в DAG.

Основные риски при работе DAG и меры по их минимизации:
1) недоступность интернет-соединения или сайта с исходным датасетом — предусмотрены повторные попытки соединения; также скачанный датасет сохраняется локально, что делает возможным его использование последующими этапами DAG даже при неработающем Интернет.
2) скачивание некорректного файла в качестве датасета — предусмотрена проверка датасета на число и тип столбцов, проверка уникальных значений таргета;
3) наличие пропусков и дублей в датасете — пропуски и дубли удаляются на этапе предобработки данных;
4)  недоступность предусмотренных в скриптах папок для хранения промежуточных данных и результатов пайплайна — операции чтения / записи выполняются через конструкцию try-except, действия логируются, при наличии ошибок на этапе в DAG предусмотрены повторные попытки запуска скрипта

Потенциальные возможности улучшения проекта:
1) реализация передачи входных параметров для DAG и скриптов отдельных этапов;
2) реализация работы с облачными хранилищами;
3) реализация авторизации и разграничения доступа пользователей.
